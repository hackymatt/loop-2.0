import json
import os
import textwrap
from types import GeneratorType
import requests
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_MODEL = "gpt-3.5-turbo"


def _build_headers():
    return {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }


def _build_payload(system_prompt, user_prompt, stream=False):
    return {
        "model": OPENAI_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        "temperature": 0,
        "max_tokens": 2000,
        "stream": stream,
    }


def send_openai_chat(system_prompt, user_prompt, timeout, stream_output=False):
    payload = _build_payload(system_prompt, user_prompt, stream=stream_output)
    headers = _build_headers()

    try:
        response = requests.post(
            OPENAI_API_URL,
            headers=headers,
            json=payload,
            timeout=timeout,
            stream=stream_output,
        )
        response.raise_for_status()

        return (
            _parse_streaming_response(response)
            if stream_output
            else _parse_non_streaming_response(response)
        )

    except requests.exceptions.RequestException as error:
        return {"stdout": "", "stderr": str(error), "exit_code": 1}
    except Exception as error:
        return {"stdout": "", "stderr": str(error), "exit_code": 1}


def _parse_non_streaming_response(response):
    try:
        result = response.json()
        content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            return {"stdout": "", "stderr": content, "exit_code": 1}
    except json.JSONDecodeError as error:
        return {
            "stdout": "",
            "stderr": f"Failed to parse response: {str(error)}",
            "exit_code": 1,
        }


def _parse_streaming_response(response):
    buffer = ""
    brace_count = 0
    for line in response.iter_lines():
        if line and line.startswith(b"data: "):
            data_str = line[len(b"data: ") :].decode("utf-8")
            if data_str == "[DONE]":
                break
            try:
                data = json.loads(data_str)
                delta = data["choices"][0].get("delta", {})
                content = delta.get("content", "")
                buffer += content

                # Count braces to detect full JSON object
                brace_count += content.count("{") - content.count("}")

                if brace_count == 0 and buffer.strip():
                    try:
                        yield json.loads(buffer)
                    except json.JSONDecodeError:
                        # Could log here
                        pass
                    buffer = ""
            except json.JSONDecodeError:
                continue


def process_job(body):
    try:
        payload = json.loads(body)
        job_id = payload.get("job_id")
        files = payload.get("files", [])
        timeout = payload.get("timeout", 10)
        command = payload.get("command")
        language = payload.get("language", "pl")
        technology = payload.get("technology")
        stream = payload.get("stream", False)

        if not job_id or not files or not command:
            raise ValueError("Missing required fields: job_id, files or command")

        file_blocks = "\n\n".join(
            (
                "' File: "
                + (file.get("path") + "/" if file.get("path") else "")
                + file["name"]
                + "\n"
                + file["code"]
            )
            for file in files
        )

        user_prompt = textwrap.dedent(
            f"""\
        Here is the {technology} code I want to run:
        {file_blocks}
        The command is: {command}

        Please simulate running this command in a {technology} environment, performing all
        calculations exactly as {technology} does.

        For each output line produced by the code, send a separate JSON object as described in
        the system prompt.

        Do NOT combine output lines into one JSON object.
        """
        )

        system_prompt = textwrap.dedent(
            f"""\
        You are an expert {technology} interpreter.
        Simulate executing the provided {technology} code.

        When you execute arithmetic expressions, calculate and return the exact, correct result as
        VBA would output it.

        Do not approximate, guess, or truncate numbers.

        For every output line generated by the code, respond immediately with a separate JSON
        object in this exact format:
        {{
        "stdout": ["<output line as string>"],
        "stderr": ["<error line as string>"],
        "exit_code": 0
        }}

        If there is an error, respond with a JSON object containing the error message in `stderr`
        and a non-zero `exit_code`.

        Do not include any markdown, code fences, explanations, or extra text.

        Send each output line as an individual JSON object.

        When all output is sent, send one final JSON object with empty `stdout` and the correct
        `exit_code`.

        Respond only in {language}.
        """
        )

        result = send_openai_chat(system_prompt, user_prompt, timeout, stream)

        return list(result) if isinstance(result, GeneratorType) else result

    except Exception as error:
        return {"error": str(error)}
